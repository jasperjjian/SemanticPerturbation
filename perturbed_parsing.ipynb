{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, pipeline\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import stanza\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "from networkx.drawing.nx_pydot import graphviz_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention(sent, model, tokenizer):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer.encode_plus(sent, return_tensors='pt')\n",
    "        input_ids = inputs['input_ids']\n",
    "        token_type_ids = inputs['token_type_ids']\n",
    "        attention = model(input_ids, token_type_ids=token_type_ids)\n",
    "    return attention[2]\n",
    "\n",
    "#convert the attention scores into a ranking\n",
    "\n",
    "def convert_to_ranking(att):\n",
    "    return torch.sort(att, descending=True)[1]\n",
    "\n",
    "#lets compare 2 sents\n",
    "\n",
    "def compare_att_dist(a1, a2): #takes the attention distribution to be the same if the attention distributions are at least 3 similar, this is a choice that can be experimented with\n",
    "    #val = bool(a1[0] == a2[0] and a2[1] == a2[1] and a1[2] == a2[2])\n",
    "    val = torch.equal(a1, a2)\n",
    "    return val\n",
    "\n",
    "def compare_three_att_dist(a1, a2, a3): #takes the attention distribution to be the same if the attention distributions are at least 3 similar, this is a choice that can be experimented with\n",
    "    #val = bool(a1[0] == a2[0] and a2[1] == a2[1] and a1[2] == a2[2])\n",
    "    val = bool(torch.equal(a1[:len(a1) // 2], a2[:len(a1) // 2])) and bool(torch.equal(a1[:len(a1) // 2], a3[:len(a1) // 2]))\n",
    "    return val\n",
    "\n",
    "def compare_atts(att1, att2, s1, s2):\n",
    "    sim_dict = {}\n",
    "    t = 0\n",
    "    similar_heads = []\n",
    "    for layer in range(12):\n",
    "        for head in range(12):\\\n",
    "            sim_dict[(layer, head)] = []\n",
    "            head_att1 = att1[layer][0][head]\n",
    "            head_att2 = att2[layer][0][head]\n",
    "            head_rank1 = convert_to_ranking(head_att1)\n",
    "            head_rank2 = convert_to_ranking(head_att2)\n",
    "            head_att3 = att3[layer][0][head]\n",
    "            head_rank3 = convert_to_ranking(head_att3)\n",
    "            for i in range(len(head_rank1)):\n",
    "            #sim_dict[str(layer+1) + \"-\" + str(head+1)].append(torch.equal(head_rank1[i], head_rank2[i]))\n",
    "                sim_dict[(layer, head)].append(compare_att_dist(head_rank1[i], head_rank2[i]))\n",
    "                t += compare_three_att_dist(head_rank1[i], head_rank2[i], head_rank3[i])\n",
    "                if compare_three_att_dist(head_rank1[i], head_rank2[i], head_rank3[i]) and (layer, head) not in similar_heads:\n",
    "                    similar_heads.append((layer, head))\n",
    "    return s1, s2, s3, t, similar_heads, sim_dict\n",
    "\n",
    "def get_best_heads(sim): #gets the heads, whose attention dist for every word are the same\n",
    "    best_heads = []\n",
    "    for k in sim.keys():\n",
    "        if sum(sim[k]) == 5:\n",
    "            best_heads.append(k)\n",
    "    return best_heads\n",
    "\n",
    "def triplet_compare(sent_list, model, tokenizer):\n",
    "  a1 = get_attention(sent_list['original'], model, tokenizer)\n",
    "  a2 = get_attention(sent_list['good'], model, tokenizer)\n",
    "  a3 = get_attention(sent_list['bad'], model, tokenizer)\n",
    "  #print(compare_atts(a1, a2, sent_list['original'], sent_list['good']))\n",
    "  sim_list = [compare_three_atts(a1, a2, a3, sent_list['original'], sent_list['good'], sent_list['bad'])]\n",
    "  return sim_list\n",
    "\n",
    "def compare_data_set(sent_list, model, tokenizer):\n",
    "  results = pd.DataFrame(columns=[\"triplet\", \"sent_1\", \"sent_2\", \"sent_3\", \"score\", \"similar_heads\", \"sim_dict\"])\n",
    "  for i, d in enumerate(sent_list):\n",
    "    result = triplet_compare(d, model, tokenizer)\n",
    "    #print(result)\n",
    "    result = [[i] + list(r) for r in result]\n",
    "    result = pd.DataFrame(result, columns=[\"triplet\", \"sent_1\", \"sent_2\", \"sent_3\", \"score\", \"similar_heads\", \"sim_dict\"])\n",
    "    results = pd.concat([results, result])\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    model_version = 'bert-base-uncased'\n",
    "    model = BertModel.from_pretrained(model_version, output_attentions=True)\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_version)\n",
    "    \n",
    "    perturb_file = open(\"/content/drive/My Drive/COMP599/perturbed_sentences.txt\")\n",
    "    file_contents = perturb_file.read()\n",
    "    perturb_sents = file_contents.splitlines()\n",
    "    perturb_sents = [{'original' : perturb_sents[i], 'good' : perturb_sents[i+1], 'bad' : perturb_sents[i+2]} for i in range(0, len(perturb_sents), 3)]\n",
    "    \n",
    "    r_three = compare_data_set(perturb_sents, model, tokenizer)\n",
    "    r_three = r_three.reset_index(drop=True)\n",
    "    sim_heads_list = list(r_three['similar_heads'])\n",
    "    \n",
    "    stanza.download('en')\n",
    "    nlp = stanza.Pipeline('en', processors='tokenize,mwt,pos,lemma,depparse', use_gpu=False, pos_batch_size=3000)\n",
    "    \n",
    "    perturb_file = open(\"/content/drive/My Drive/COMP599/perturbed_sentences.txt\")\n",
    "    file_contents = perturb_file.read()\n",
    "    perturb_sents_list = file_contents.splitlines()\n",
    "    all_sents = \"\\n\\n\".join(perturb_sents_list)\n",
    "    doc_all = nlp(all_sents) # Run the pipeline on the input text\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (default-env)",
   "language": "python",
   "name": "default-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
